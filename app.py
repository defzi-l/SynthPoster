import gradio as gr
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from dotenv import load_dotenv 
import urllib.parse
from urllib.parse import urlparse
import requests
from io import BytesIO
import socket
import openai
import torch
from typing import Optional
from PIL import Image
import dashscope
from dashscope import ImageSynthesis

# ==================== 1. ä»ç¯å¢ƒå˜é‡åŠ è½½è®¾ç½® ====================
load_dotenv() 

# ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼ˆé˜²æ­¢æŠ¥é”™ï¼‰
LLM_API_KEY = os.getenv("LLM_API_KEY", "")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "qwen-max")  # ä½¿ç”¨å…¼å®¹çš„é»˜è®¤æ¨¡å‹

# æ£€æŸ¥å…³é”®å¯†é’¥æ˜¯å¦å·²è®¾ç½®
if not LLM_API_KEY:
    raise ValueError("è¯·åœ¨ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½® 'LLM_API_KEY'")

# åˆå§‹åŒ–LLMæ¨¡å‹
llm = ChatOpenAI(
    model=LLM_MODEL_NAME,
    openai_api_key=LLM_API_KEY,
    openai_api_base=LLM_BASE_URL if LLM_BASE_URL else None,
    temperature=0.7,
)

dashscope.api_key = LLM_API_KEY

# å®šä¹‰å›¾åƒç”Ÿæˆå‡½æ•° (å¢å¼ºé”™è¯¯å¤„ç†ç‰ˆæœ¬)
def generate_image_from_prompt(prompt: str) -> Optional[Image.Image]:
    """
    ä½¿ç”¨é€šä¹‰åƒé—® Qwen-Image API ç”Ÿæˆå›¾åƒï¼Œå¹¶å®ç°å¼‚æ­¥è½®è¯¢ã€‚
    è¿”å›PIL Imageå¯¹è±¡ï¼Œå¦‚æœç”Ÿæˆå¤±è´¥åˆ™è¿”å›Noneã€‚
    """
    import time
    
    try:
        print(f"[Qwen-Image API] æäº¤ä»»åŠ¡ï¼Œæç¤ºè¯: {prompt[:80]}...")

        # 1. æäº¤å¼‚æ­¥ç”Ÿæˆä»»åŠ¡
        resp = ImageSynthesis.async_call(
            model='qwen-image-plus',  # æˆ– 'qwen-image'
            prompt=prompt,
            size='1664*928',  # 16:9 æ¨ªç‰ˆï¼Œå¯¹åº”ä½ çš„ `(Landscape poster)`
            n=1,
            prompt_extend=False
        )

        # æ£€æŸ¥åˆå§‹å“åº”æ˜¯å¦æˆåŠŸ
        if resp.status_code != 200 or not hasattr(resp, 'output') or not hasattr(resp.output, 'task_id'):
            error_msg = getattr(resp, 'message', f'HTTP {resp.status_code}')
            print(f"[Qwen-Image API] ä»»åŠ¡æäº¤å¤±è´¥: {error_msg}")
            return None

        task_id = resp.output.task_id
        print(f"[Qwen-Image API] ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}")

        # 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼Œç›´åˆ°å®Œæˆã€å¤±è´¥æˆ–è¶…æ—¶
        max_wait_time = 120  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ ¹æ®å…è´¹é¢åº¦æ€§èƒ½è°ƒæ•´
        poll_interval = 3    # è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        start_time = time.time()

        while time.time() - start_time < max_wait_time:
            # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
            status_resp = ImageSynthesis.fetch(task_id)
            
            if status_resp.status_code != 200:
                print(f"[Qwen-Image API] æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {status_resp.status_code}")
                break

            task_status = status_resp.output.task_status
            print(f"[Qwen-Image API] è½®è¯¢ä¸­... ä»»åŠ¡çŠ¶æ€: {task_status}")

            if task_status == 'SUCCEEDED':
                # ä»»åŠ¡æˆåŠŸï¼Œè·å–ç»“æœ
                if hasattr(status_resp.output, 'results') and status_resp.output.results:
                    image_url = status_resp.output.results[0].url
                    print(f"[Qwen-Image API] å›¾åƒç”ŸæˆæˆåŠŸï¼Œå¼€å§‹ä¸‹è½½...")
                    # ä¸‹è½½å›¾ç‰‡
                    image_response = requests.get(image_url, timeout=30)
                    if image_response.status_code == 200:
                        image = Image.open(BytesIO(image_response.content))
                        print("âœ… å›¾åƒä¸‹è½½å¹¶è½¬æ¢æˆåŠŸ")
                        return image
                    else:
                        print(f"[Qwen-Image API] ä¸‹è½½å›¾ç‰‡å¤±è´¥: {image_response.status_code}")
                        return None
                else:
                    print("[Qwen-Image API] ä»»åŠ¡æˆåŠŸä½†æ— ç»“æœã€‚")
                    return None
                    
            elif task_status == 'FAILED':
                # ä»»åŠ¡å¤±è´¥
                error_msg = getattr(status_resp.output, 'message', 'æœªçŸ¥é”™è¯¯')
                print(f"[Qwen-Image API] ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {error_msg}")
                return None
                
            # å¦‚æœä»»åŠ¡ä»åœ¨è¿è¡Œæˆ–ç­‰å¾…ï¼Œåˆ™ç»§ç»­è½®è¯¢
            elif task_status in ['PENDING', 'RUNNING']:
                time.sleep(poll_interval)
                continue
                
            else:
                # é‡åˆ°æœªçŸ¥çŠ¶æ€
                print(f"[Qwen-Image API] ä»»åŠ¡è¿›å…¥æœªçŸ¥çŠ¶æ€: {task_status}")
                break

        # å¾ªç¯ç»“æŸï¼Œè¡¨ç¤ºè¶…æ—¶
        print(f"[Qwen-Image API] é”™è¯¯ï¼šè½®è¯¢è¶…æ—¶ï¼ˆ{max_wait_time}ç§’ï¼‰ï¼Œä»»åŠ¡å¯èƒ½ä»åœ¨å¤„ç†æˆ–å·²å¡ä½ã€‚")
        return None

    except Exception as e:
        print(f"[Qwen-Image API] å›¾åƒç”Ÿæˆè¿‡ç¨‹å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None

def network_test():
    """æµ‹è¯•Spaceå®¹å™¨çš„ç½‘ç»œè¿æ¥"""
    results = []
    
    # æµ‹è¯•1ï¼šæµ‹è¯•Vercelä»£ç†
    try:
        proxy_url = LLM_BASE_URL
        response = requests.post(
            proxy_url,
            json={"model": "qwen-max", "messages": [{"role": "user", "content": "test"}]},
            timeout=10
        )
        results.append(f"âœ… ä»£ç†è¿æ¥æˆåŠŸ: çŠ¶æ€ç  {response.status_code}")
    except Exception as e:
        results.append(f"âŒ ä»£ç†è¿æ¥å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•2ï¼šæµ‹è¯•DNSè§£æ
    if LLM_BASE_URL:
        try:
            # ä½¿ç”¨urlparseæå–åŸŸå
            parsed_url = urlparse(LLM_BASE_URL)
            domain = parsed_url.netloc  # è¿™å°†å¾—åˆ°ç±»ä¼¼ "qwen-proxy-psi.vercel.app"
            
            # å¦‚æœURLä¸­åŒ…å«ç«¯å£å·ï¼Œéœ€è¦å»æ‰ç«¯å£éƒ¨åˆ†
            if ':' in domain:
                domain = domain.split(':')[0]
                
            ip = socket.gethostbyname(domain)
            results.append(f"âœ… DNSè§£ææˆåŠŸ: {domain} â†’ {ip}")
        except Exception as e:
            results.append(f"âŒ DNSè§£æå¤±è´¥ ({domain}): {e}")
    else:
        results.append("âš ï¸  LLM_BASE_URLæœªè®¾ç½®ï¼Œè·³è¿‡DNSè§£ææµ‹è¯•")
    
    # æµ‹è¯•3ï¼šæµ‹è¯•åŸºç¡€ç½‘ç»œè¿é€šæ€§
    try:
        response = requests.get("https://httpbin.org/ip", timeout=5)
        results.append(f"âœ… åŸºç¡€ç½‘ç»œæ­£å¸¸: {response.status_code}")
    except Exception as e:
        results.append(f"âŒ åŸºç¡€ç½‘ç»œå¼‚å¸¸: {e}")
    
    # æµ‹è¯•4ï¼šæµ‹è¯•æ˜¯å¦è¢«é˜²ç«å¢™é˜»æŒ¡
    try:
        # å°è¯•è®¿é—®ä¸åŒç«¯å£
        response = requests.get("https://httpbin.org/headers", timeout=5)
        results.append(f"âœ… HTTPè¯·æ±‚æ­£å¸¸: {response.status_code}")
    except Exception as e:
        results.append(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {e}")
    
    return "\n".join(results)

# ==================== 2. å®šä¹‰ä¸‰ä¸ªæ™ºèƒ½ä½“çš„æç¤ºæ¨¡æ¿ ====================
# æ™ºèƒ½ä½“1ï¼šæ‹†è§£æ™ºèƒ½ä½“ - ç†è§£éœ€æ±‚ï¼Œæ‹†è§£æ ¸å¿ƒå…ƒç´ 
decompose_prompt = ChatPromptTemplate.from_template(
    """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„åˆ›æ„ç­–åˆ’ã€‚è¯·å°†ç”¨æˆ·æ¨¡ç³Šçš„åˆ›æ„æè¿°ï¼Œæ‹†è§£æˆå›¾åƒç”Ÿæˆæ‰€éœ€çš„å…·ä½“ã€å¯æ‰§è¡Œçš„æ ¸å¿ƒå…ƒç´ åˆ—è¡¨ã€‚
    ç”¨æˆ·æè¿°ï¼š{user_input}
    è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆï¼š
    **ä¸»é¢˜**ï¼š[ç”¨ä¸€å¥è¯æ¦‚æ‹¬æ ¸å¿ƒä¸»é¢˜]
    **ä¸»è¦å…ƒç´ **ï¼š[åˆ—å‡º3-5ä¸ªå…³é”®è§†è§‰å…ƒç´ ï¼Œç”¨é€—å·åˆ†éš”]
    **æ°›å›´**ï¼š[æè¿°ç”»é¢æ•´ä½“æ°›å›´ï¼Œå¦‚"ç§‘å¹»ã€æ¸©æš–ã€è‚ƒç©†"]
    """
)

# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_decompose = decompose_prompt | llm

# æ™ºèƒ½ä½“2ï¼šä¼˜åŒ–æ™ºèƒ½ä½“ - å°†å…ƒç´ è½¬åŒ–ä¸ºä¸“ä¸šå›¾åƒæç¤ºè¯
optimize_prompt = ChatPromptTemplate.from_template(
    """
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„AIç»˜ç”»æç¤ºè¯å·¥ç¨‹å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹åˆ›æ„æ‹†è§£ï¼Œå°†å…¶ä¼˜åŒ–æˆä¸€æ®µè¯¦ç»†ã€é«˜è´¨é‡çš„è‹±æ–‡AIç»˜ç”»æç¤ºè¯ã€‚
    è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
    1. æç¤ºè¯ä¸ºè‹±æ–‡ï¼Œæè¿°ç»†è‡´ã€‚
    2. åŒ…å«ç”»é¢ä¸»ä½“ã€ç»†èŠ‚ã€é£æ ¼ã€è‰²è°ƒã€æ„å›¾ã€ç”»è´¨ç­‰ã€‚
    3. ç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚

    åˆ›æ„æ‹†è§£ï¼š
    {decomposed}
    ä¼˜åŒ–åçš„ä¸“ä¸šæç¤ºè¯ï¼š
    """
)
# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_optimize = optimize_prompt | llm

# æ™ºèƒ½ä½“3ï¼šå‡çº§ä¸ºâ€œæµ·æŠ¥è®¾è®¡å¸ˆâ€æ™ºèƒ½ä½“ - ç›´æ¥ç”Ÿæˆæµ·æŠ¥é£æ ¼çš„æç¤ºè¯
review_prompt = ChatPromptTemplate.from_template(
    """
    You are a professional graphic designer creating posters for campus events with AI.

    ã€Core Taskã€‘
    Generate ONE concise, effective English prompt for an AI image model to create a complete poster based on the event description.

    ã€Input Analysis & Smart Decisionsã€‘
    1.  **Size & Orientation (CRITICAL):** Analyze the following Chinese or English keywords in the description to decide the poster format. Integrate the chosen format like `(portrait poster)` or `(wide landscape poster)` into your final prompt.
        - Keywords for **Portrait**: `ç«–ç‰ˆ`, `ç«–å‘`, `portrait`, `vertical` -> Choose **portrait (9:16)**
        - Keywords for **Square**: `æ–¹å‹`, `æ–¹å½¢`, `æ­£æ–¹å½¢`, `square` -> Choose **square (1:1)**
        - Keywords for **Landscape**: `æ¨ªç‰ˆ`, `æ¨ªå‘`, `landscape`, `wide` -> Choose **landscape (16:9)**
        - **If no keywords are found, default to landscape (16:9).**

    2.  **Layout & Content (STRUCTURED):** Your prompt must describe a poster with these clear sections:
        - **MAIN HEADER:** A dominant, clear title area at the top. **If the description contains a title, use it. If not, invent a compelling, relevant title** (e.g., "Neural Nexus: AI Lecture Series" for an AI talk).
        - **INFORMATION BLOCK:** A dedicated area with event details (time, date, venue). **If details are provided, use them. If not, fabricate plausible, specific details** (e.g., "Date: Apr 15 | Time: 6:00 PM | Location: University Hall 203").
        - **CENTRAL VISUAL:** **One single, strong, symbolic icon/graphic** representing the event's core idea (e.g., interlocking gears for collaboration, a stylized brain for psychology). DO NOT describe a complex scene.
        - **CLEAR TYPOGRAPHY ZONES:** Visually separate the header, info block, and background. Use phrases like "clear typography," "distinct text areas," "bold header."

    3.  **Style & Atmosphere (CREATIVE):**
        - **Base Style:** "vector illustration", "flat design", "modern minimalist poster" â€“ ensuring clarity for the AI model.
        - **Color & Mood:** Choose a color palette fitting the event's nature (cool blues/grays for academic, warm vibrant colors for festivals/arts).
        - **Random Artistic Flair (IMPORTANT):** **Randomly select and integrate ONE** of these styles to add uniqueness: `pop art`, `retro vintage`, `cyberpunk glow`, `watercolor splash`, `linocut print`.

    ã€Strict Output Rulesã€‘
    - Output **ONLY the final image generation prompt**. No explanations, prefixes, or additional text.
    - The prompt must be in **English**.
    - **Strictly limit to 70 English words.** Be concise and powerful.

    ã€Example Prompt Structureã€‘
    "(Portrait poster) with a bold header 'AI Symposium 2024' and a lower info block stating 'Date: Nov 20 | Venue: Tech Center'. Central visual of a glowing, interconnected network nodes. Clean vector illustration, flat design with a cool blue and purple gradient, in a retro vintage style. Clear typography areas, minimalist layout."

    ã€Event Description to Analyzeã€‘
    {prompt}

    ã€Your Output (ONLY the image prompt)ã€‘
    """
)
# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_review = review_prompt | llm

# ==================== 3. é‡æ„ï¼šæ¸…æ™°ã€åˆ†æ­¥çš„ååŒå·¥ä½œæµ ====================

def run_agent_chain(user_input: str):
    """
    åˆ†æ­¥æ‰§è¡Œæ™ºèƒ½ä½“é“¾ï¼Œæ¯ä¸€æ­¥éƒ½æ˜ç¡®å¤„ç†è¾“å…¥è¾“å‡ºï¼Œæ˜“äºè°ƒè¯•ã€‚
    è¿”å›: (decomposed_text, optimized_prompt, final_prompt)
    """
    print(f"[STEP 0] å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}")
    
    # ç¬¬ä¸€æ­¥ï¼šæ‹†è§£
    try:
        print(f"[STEP 1] è°ƒç”¨ chain_decompose...")
        # æ˜ç¡®æ„é€ è¾“å…¥å­—å…¸
        step1_result = chain_decompose.invoke({"user_input": user_input})
        decomposed_text = step1_result.content
        print(f"[STEP 1] æˆåŠŸã€‚ç»“æœ: {decomposed_text[:50]}...")  # æ‰“å°å‰50å­—ç¬¦
    except Exception as e:
        print(f"[STEP 1] å¤±è´¥: {e}")
        decomposed_text = f"æ‹†è§£å¤±è´¥: {e}"
        return decomposed_text, "", ""  # æå‰è¿”å›ï¼Œå› ä¸ºåç»­æ­¥éª¤ä¾èµ–æ­¤ç»“æœ
    
    # ç¬¬äºŒæ­¥ï¼šä¼˜åŒ–
    try:
        print(f"[STEP 2] è°ƒç”¨ chain_optimize...")
        # æ˜ç¡®ä½¿ç”¨ä¸Šä¸€æ­¥çš„ç»“æœä½œä¸ºè¾“å…¥
        step2_result = chain_optimize.invoke({"decomposed": decomposed_text})
        optimized_prompt = step2_result.content
        print(f"[STEP 2] æˆåŠŸã€‚ç»“æœ: {optimized_prompt[:50]}...")
    except Exception as e:
        print(f"[STEP 2] å¤±è´¥: {e}")
        optimized_prompt = f"ä¼˜åŒ–å¤±è´¥: {e}"
        return decomposed_text, optimized_prompt, ""
    
    # ç¬¬ä¸‰æ­¥ï¼šé£æ ¼åŒ– (å‡çº§ä¸ºæµ·æŠ¥è®¾è®¡)
    try:
        print(f"[STEP 3] è°ƒç”¨æµ·æŠ¥è®¾è®¡å¸ˆæ™ºèƒ½ä½“...")
        # ç›´æ¥å°†ä¼˜åŒ–åçš„è‹±æ–‡æç¤ºè¯ä¼ é€’ç»™æ–°çš„ review_prompt
        # æ–°çš„ prompt å°†è‡ªè¡Œä»ä¸­æ–‡å…³é”®è¯ä¸­è§£æå°ºå¯¸ã€å¹¶è¡¥å…¨ä¿¡æ¯
        step3_result = chain_review.invoke({"prompt": optimized_prompt}) # æ³¨æ„å˜é‡åæ˜¯ "prompt"
        final_prompt = step3_result.content.strip()
        
        word_count = len(final_prompt.split())
        print(f"[STEP 3] æµ·æŠ¥æç¤ºè¯ç”ŸæˆæˆåŠŸ (å•è¯æ•°: {word_count})ã€‚å†…å®¹é¢„è§ˆ: {final_prompt[:80]}...")
        
    except Exception as e:
        print(f"[STEP 3] å¤±è´¥: {e}")
        final_prompt = f"æµ·æŠ¥è®¾è®¡å¤±è´¥: {e}"
    
    return decomposed_text, optimized_prompt, final_prompt

# ==================== 4. æ›´æ–°Gradioç•Œé¢äº¤äº’å‡½æ•° ====================
def generate_poster(user_input):
    """ å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œè¿è¡Œæ™ºèƒ½ä½“é“¾ï¼Œå¹¶è¿”å›ç»“æœ """
    # è°ƒç”¨æˆ‘ä»¬ä¸Šé¢å®šä¹‰çš„åˆ†æ­¥å‡½æ•°
    decomposed_text, optimized_prompt, final_prompt_full = run_agent_chain(user_input)
    
    # æœ€ç»ˆæç¤ºè¯
    final_image_prompt = final_prompt_full.strip()
    
    # å›¾åƒéƒ¨åˆ†æš‚æ—¶ä¸ºç©º
    generated_image = None
    if final_image_prompt and not final_image_prompt.startswith("é£æ ¼åŒ–å¤±è´¥"):
        # ä»…å½“æˆåŠŸè·å¾—æç¤ºè¯æ—¶æ‰å°è¯•ç”Ÿæˆå›¾åƒ
        print(f"[å›¾åƒç”Ÿæˆ] æœ€ç»ˆä½¿ç”¨æç¤ºè¯ (é•¿åº¦{len(final_image_prompt.split())}è¯): {final_image_prompt[:60]}...")
        generated_image = generate_image_from_prompt(final_image_prompt)
    
    # è¿”å›ç»™Gradioæ˜¾ç¤º
    # æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯ decomposed_text, optimized_prompt, final_prompt_full
    return decomposed_text, optimized_prompt, final_prompt_full, generated_image

# ==================== 5. æ„å»ºå¹¶å¯åŠ¨Gradio Webç•Œé¢ ====================
with gr.Blocks(title="SynthPoster") as demo:
    gr.Markdown("# ğŸ¨ æ™ºæ±‡æµ·æŠ¥ æµ·æŠ¥åˆ›ä½œæ™ºèƒ½ä½“ååŒç³»ç»Ÿ")
    gr.Markdown("ä½“éªŒä¸‰ä¸ªAIæ™ºèƒ½ä½“å¦‚ä½•ååŒå·¥ä½œï¼šæ‹†è§£ â†’ ä¼˜åŒ– â†’ é£æ ¼åŒ–")

    with gr.Row():
        with gr.Column():
            user_input = gr.Textbox(
                label="æè¿°ä½ æƒ³ç”Ÿæˆçš„æµ·æŠ¥",
                placeholder="ä¾‹å¦‚ï¼šAIæ¨¡å‹ååŒè®²åº§",
                lines=3
            )
            btn = gr.Button("ğŸš€ å¼€å§‹ååŒåˆ›ä½œ", variant="primary")

        with gr.Column():
            output_image = gr.Image(label="ç”Ÿæˆçš„æµ·æŠ¥", width=512)

    with gr.Accordion("ğŸ“ ç‚¹å‡»æŸ¥çœ‹æ™ºèƒ½ä½“ååŒçš„å®Œæ•´è¿‡ç¨‹", open=False):
        output_decomposed = gr.Textbox(label="æ™ºèƒ½ä½“1 - åˆ›æ„æ‹†è§£", lines=3)
        output_optimized = gr.Textbox(label="æ™ºèƒ½ä½“2 - æç¤ºè¯ä¼˜åŒ–", lines=3)
        output_final = gr.Textbox(label="æ™ºèƒ½ä½“3 - é£æ ¼å®šç¨¿", lines=3)

    # ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
    btn.click(
        fn=generate_poster,
        inputs=[user_input],
        outputs=[output_decomposed, output_optimized, output_final, output_image]
    )
    
    # æ·»åŠ æµ‹è¯•éƒ¨åˆ†
    gr.Markdown("## ç½‘ç»œè¯Šæ–­å·¥å…·")
    test_btn = gr.Button("è¿è¡Œç½‘ç»œæµ‹è¯•")
    test_output = gr.Textbox(label="æµ‹è¯•ç»“æœ", lines=10)
    test_btn.click(network_test, outputs=test_output)

     # ==================== æ–°å¢ï¼šAPIè¿é€šæ€§æµ‹è¯•åŠŸèƒ½åŒº ====================
    with gr.Accordion("ğŸ”§ APIè¿é€šæ€§æµ‹è¯•ï¼ˆè°ƒè¯•ä¸“ç”¨ï¼‰", open=False):
        gr.Markdown("""
        **ä½¿ç”¨è¯´æ˜**ï¼šæ­¤åŠŸèƒ½å°†ç»•è¿‡LangChainï¼Œç›´æ¥è°ƒç”¨ä½ é…ç½®çš„åƒé—®APIã€‚
        1. ç‚¹å‡»æµ‹è¯•æŒ‰é’®ã€‚
        2. ä¸‹æ–¹å°†æ˜¾ç¤ºï¼š**ä½ çš„é…ç½®**ã€**APIåŸå§‹å“åº”**ã€**å¤„ç†åçš„ç­”æ¡ˆ**ã€‚
        3. å¦‚æœå¤±è´¥ï¼Œä¼šæ˜¾ç¤ºå…·ä½“é”™è¯¯ï¼Œè¯·æ ¸å¯¹é…ç½®ï¼ˆç‰¹åˆ«æ˜¯Base URLå’Œæ¨¡å‹åï¼‰ã€‚
        """)
        test_btn = gr.Button("ğŸ§ª æµ‹è¯•APIè¿æ¥", variant="secondary")
        test_output_config = gr.Textbox(label="ä½ çš„APIé…ç½®", lines=3, interactive=False)
        test_output_raw = gr.Textbox(label="APIåŸå§‹å“åº”", lines=5, interactive=False)
        test_output_content = gr.Textbox(label="å¤„ç†åçš„å›ç­”", lines=2, interactive=False)

        # å®šä¹‰æµ‹è¯•å‡½æ•°
        def test_api_connection():
            config_info = f"""æ­£åœ¨æµ‹è¯•çš„é…ç½®ï¼š
    API_KEYå‰5ä½: {LLM_API_KEY[:5] if LLM_API_KEY else 'None'}...
    BASE_URL: {LLM_BASE_URL}
    MODEL_NAME: {LLM_MODEL_NAME}
    """
            try:
                # 1. åˆå§‹åŒ–openaiå®¢æˆ·ç«¯
                client = openai.OpenAI(
                    api_key=LLM_API_KEY,
                    base_url=LLM_BASE_URL.rstrip('/')  # ç§»é™¤æœ«å°¾å¯èƒ½å­˜åœ¨çš„æ–œæ 
                )
                
                # 2. å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                test_messages = [{"role": "user", "content": "è¯·ç”¨ä¸­æ–‡ç®€çŸ­å›å¤ï¼šAPIè¿æ¥æµ‹è¯•æˆåŠŸã€‚"}]
                # è®¾ç½®æ˜ç¡®çš„è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´æŒ‚èµ·
                response = client.chat.completions.create(
                    model=LLM_MODEL_NAME,
                    messages=test_messages,
                    temperature=0.7,
                    timeout=10.0  # 10ç§’è¶…æ—¶
                )
                
                # 3. æ•´ç†å¹¶è¿”å›ç»“æœ
                raw_response = f"å“åº”å¯¹è±¡ç±»å‹: {type(response)}\n"
                raw_response += f"æ˜¯å¦æ”¶åˆ°å“åº”: {hasattr(response, 'choices')}\n"
                if hasattr(response, 'choices') and len(response.choices) > 0:
                    raw_response += f"choices ç»“æ„: {response.choices[0]}"
                
                answer = response.choices[0].message.content
                return config_info, raw_response, answer
                
            except openai.AuthenticationError as e:
                error_detail = f"{config_info}\n\nâŒ è®¤è¯å¤±è´¥ (å¯èƒ½åŸå› ):\n1. API_KEY æ— æ•ˆæˆ–å·²è¿‡æœŸ\n2. æœªå¼€é€šå¯¹åº”æ¨¡å‹æœåŠ¡\n3. æœåŠ¡åŒºåŸŸä¸æ­£ç¡®\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "è®¤è¯å¤±è´¥"
            except openai.NotFoundError as e:
                error_detail = f"{config_info}\n\nâŒ æœªæ‰¾åˆ°èµ„æº (å¯èƒ½åŸå› ):\n1. MODEL_NAME '{LLM_MODEL_NAME}' ä¸æ­£ç¡®\n2. BASE_URL è·¯å¾„é”™è¯¯\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "æ¨¡å‹æˆ–ç«¯ç‚¹ä¸å­˜åœ¨"
            except openai.APIConnectionError as e:
                error_detail = f"{config_info}\n\nğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥ (å¯èƒ½åŸå› ):\n1. BASE_URL æ— æ³•è®¿é—®\n2. ç½‘ç»œä»£ç†é—®é¢˜\n3. Hugging Face Space å®¹å™¨ç½‘ç»œé™åˆ¶\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "ç½‘ç»œè¿æ¥å¤±è´¥"
            except Exception as e:
                error_detail = f"{config_info}\n\nâš ï¸ æœªé¢„æœŸçš„é”™è¯¯:\né”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯è¯¦æƒ…: {str(e)}"
                return error_detail, str(e), f"è°ƒç”¨å¤±è´¥: {type(e).__name__}"
        
        # ç»‘å®šæµ‹è¯•æŒ‰é’®äº‹ä»¶
        test_btn.click(
            fn=test_api_connection,
            inputs=[],
            outputs=[test_output_config, test_output_raw, test_output_content]
        )

# è¿è¡Œ
if __name__ == "__main__":
    # åˆ¤æ–­æ˜¯å¦åœ¨ Hugging Face Space ç¯å¢ƒä¸­è¿è¡Œ
    if os.getenv("SPACE_ID") is not None:
        # ğŸš€ Space ç¯å¢ƒï¼šä½¿ç”¨é»˜è®¤çš„ launch() é…ç½®ï¼Œæ— éœ€ä»»ä½•å‚æ•°
        # Space ä¼šè‡ªåŠ¨å¤„ç†ç½‘ç»œã€ç«¯å£ç­‰æ‰€æœ‰é…ç½®
        demo.launch()
    else:
        # ğŸ’» æœ¬åœ°å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨ä½ åŸæ¥çš„é…ç½®
        demo.launch(server_name="127.0.0.1", server_port=7860, share=False)