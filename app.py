import gradio as gr
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from dotenv import load_dotenv 
import urllib.parse
from urllib.parse import urlparse
import requests
import socket

# ==================== 1. ä»ç¯å¢ƒå˜é‡åŠ è½½è®¾ç½® ====================
load_dotenv() 

# ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼ˆé˜²æ­¢æŠ¥é”™ï¼‰
LLM_API_KEY = os.getenv("LLM_API_KEY", "")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "qwen-max")  # ä½¿ç”¨å…¼å®¹çš„é»˜è®¤æ¨¡å‹

# æ£€æŸ¥å…³é”®å¯†é’¥æ˜¯å¦å·²è®¾ç½®
if not LLM_API_KEY:
    raise ValueError("è¯·åœ¨ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½® 'LLM_API_KEY'")

# åˆå§‹åŒ–LLMæ¨¡å‹
llm = ChatOpenAI(
    model=LLM_MODEL_NAME,
    openai_api_key=LLM_API_KEY,
    openai_api_base=LLM_BASE_URL if LLM_BASE_URL else None,
    temperature=0.7,
)


def network_test():
    """æµ‹è¯•Spaceå®¹å™¨çš„ç½‘ç»œè¿æ¥"""
    results = []
    
    # æµ‹è¯•1ï¼šæµ‹è¯•Vercelä»£ç†
    try:
        proxy_url = LLM_BASE_URL
        response = requests.post(
            proxy_url,
            json={"model": "qwen-max", "messages": [{"role": "user", "content": "test"}]},
            timeout=10
        )
        results.append(f"âœ… ä»£ç†è¿æ¥æˆåŠŸ: çŠ¶æ€ç  {response.status_code}")
    except Exception as e:
        results.append(f"âŒ ä»£ç†è¿æ¥å¤±è´¥: {str(e)}")
    
    # æµ‹è¯•2ï¼šæµ‹è¯•DNSè§£æ
    if LLM_BASE_URL:
        try:
            # ä½¿ç”¨urlparseæå–åŸŸå
            parsed_url = urlparse(LLM_BASE_URL)
            domain = parsed_url.netloc  # è¿™å°†å¾—åˆ°ç±»ä¼¼ "qwen-proxy-psi.vercel.app"
            
            # å¦‚æœURLä¸­åŒ…å«ç«¯å£å·ï¼Œéœ€è¦å»æ‰ç«¯å£éƒ¨åˆ†
            if ':' in domain:
                domain = domain.split(':')[0]
                
            ip = socket.gethostbyname(domain)
            results.append(f"âœ… DNSè§£ææˆåŠŸ: {domain} â†’ {ip}")
        except Exception as e:
            results.append(f"âŒ DNSè§£æå¤±è´¥ ({domain}): {e}")
    else:
        results.append("âš ï¸  LLM_BASE_URLæœªè®¾ç½®ï¼Œè·³è¿‡DNSè§£ææµ‹è¯•")
    
    # æµ‹è¯•3ï¼šæµ‹è¯•åŸºç¡€ç½‘ç»œè¿é€šæ€§
    try:
        response = requests.get("https://httpbin.org/ip", timeout=5)
        results.append(f"âœ… åŸºç¡€ç½‘ç»œæ­£å¸¸: {response.status_code}")
    except Exception as e:
        results.append(f"âŒ åŸºç¡€ç½‘ç»œå¼‚å¸¸: {e}")
    
    # æµ‹è¯•4ï¼šæµ‹è¯•æ˜¯å¦è¢«é˜²ç«å¢™é˜»æŒ¡
    try:
        # å°è¯•è®¿é—®ä¸åŒç«¯å£
        response = requests.get("https://httpbin.org/headers", timeout=5)
        results.append(f"âœ… HTTPè¯·æ±‚æ­£å¸¸: {response.status_code}")
    except Exception as e:
        results.append(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {e}")
    
    return "\n".join(results)

# ==================== 2. å®šä¹‰ä¸‰ä¸ªæ™ºèƒ½ä½“çš„æç¤ºæ¨¡æ¿ ====================
# æ™ºèƒ½ä½“1ï¼šæ‹†è§£æ™ºèƒ½ä½“ - ç†è§£éœ€æ±‚ï¼Œæ‹†è§£æ ¸å¿ƒå…ƒç´ 
decompose_prompt = ChatPromptTemplate.from_template(
    """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„åˆ›æ„ç­–åˆ’ã€‚è¯·å°†ç”¨æˆ·æ¨¡ç³Šçš„åˆ›æ„æè¿°ï¼Œæ‹†è§£æˆå›¾åƒç”Ÿæˆæ‰€éœ€çš„å…·ä½“ã€å¯æ‰§è¡Œçš„æ ¸å¿ƒå…ƒç´ åˆ—è¡¨ã€‚
    ç”¨æˆ·æè¿°ï¼š{user_input}
    è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆï¼š
    **ä¸»é¢˜**ï¼š[ç”¨ä¸€å¥è¯æ¦‚æ‹¬æ ¸å¿ƒä¸»é¢˜]
    **ä¸»è¦å…ƒç´ **ï¼š[åˆ—å‡º3-5ä¸ªå…³é”®è§†è§‰å…ƒç´ ï¼Œç”¨é€—å·åˆ†éš”]
    **æ°›å›´**ï¼š[æè¿°ç”»é¢æ•´ä½“æ°›å›´ï¼Œå¦‚"ç§‘å¹»ã€æ¸©æš–ã€è‚ƒç©†"]
    """
)

# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_decompose = decompose_prompt | llm

# æ™ºèƒ½ä½“2ï¼šä¼˜åŒ–æ™ºèƒ½ä½“ - å°†å…ƒç´ è½¬åŒ–ä¸ºä¸“ä¸šå›¾åƒæç¤ºè¯
optimize_prompt = ChatPromptTemplate.from_template(
    """
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„AIç»˜ç”»æç¤ºè¯å·¥ç¨‹å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹åˆ›æ„æ‹†è§£ï¼Œå°†å…¶ä¼˜åŒ–æˆä¸€æ®µè¯¦ç»†ã€é«˜è´¨é‡çš„è‹±æ–‡AIç»˜ç”»æç¤ºè¯ã€‚
    è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
    1. æç¤ºè¯ä¸ºè‹±æ–‡ï¼Œæè¿°ç»†è‡´ã€‚
    2. åŒ…å«ç”»é¢ä¸»ä½“ã€ç»†èŠ‚ã€é£æ ¼ã€è‰²è°ƒã€æ„å›¾ã€ç”»è´¨ç­‰ã€‚
    3. ç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚

    åˆ›æ„æ‹†è§£ï¼š
    {decomposed}
    ä¼˜åŒ–åçš„ä¸“ä¸šæç¤ºè¯ï¼š
    """
)
# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_optimize = optimize_prompt | llm

# æ™ºèƒ½ä½“3ï¼šå®¡æŸ¥/é£æ ¼åŒ–æ™ºèƒ½ä½“ - ä¸ºæç¤ºè¯æ·»åŠ ç»Ÿä¸€é£æ ¼
review_prompt = ChatPromptTemplate.from_template(
    """
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ ¡å›­æ´»åŠ¨è‰ºæœ¯æ€»ç›‘ã€‚è¯·æ ¹æ®ç”¨æˆ·å¯¹æ´»åŠ¨æµ·æŠ¥çš„æè¿°ï¼Œåˆ¤æ–­å…¶æ´»åŠ¨ç±»å‹ï¼Œå¹¶ä¸ºå…¶ä¼˜åŒ–å’Œå®šå‹AIç»˜ç”»æç¤ºè¯ï¼Œä½¿å…¶ç¬¦åˆè¯¥ç±»æ ¡å›­æµ·æŠ¥çš„ä¸“ä¸šé£æ ¼ã€‚

    è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼š
    1. **åˆ¤æ–­æ´»åŠ¨ç±»å‹**ï¼šæ ¹æ®æè¿°ï¼Œä»ä»¥ä¸‹å¸¸è§ç±»å‹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ï¼Œæˆ–æ¨æ–­ä¸€ä¸ªåˆç†çš„ç±»å‹ï¼š
       - **å­¦æœ¯ç±»**ï¼ˆå¦‚è®²åº§ã€ç ”è®¨ä¼šã€ç«èµ›ï¼‰
       - **æ‹›å‹Ÿç±»**ï¼ˆå¦‚ç¤¾å›¢æ‹›æ–°ã€å¿—æ„¿è€…æ‹›å‹Ÿã€é˜Ÿå‘˜æ‹›å‹Ÿï¼‰
       - **æ–‡è‰ºç±»**ï¼ˆå¦‚éŸ³ä¹ä¼šã€è¯å‰§ã€èˆè¹ˆæ¼”å‡ºã€ç”»å±•ï¼‰
       - **åº†å…¸èŠ‚æ—¥ç±»**ï¼ˆå¦‚è¿æ–°æ™šä¼šã€æ¯•ä¸šå­£ã€åœ£è¯æ´¾å¯¹ã€æ ¡åº†ï¼‰
       - **ä½“è‚²å¥èº«ç±»**ï¼ˆå¦‚è¿åŠ¨ä¼šã€ç¯®çƒèµ›ã€é©¬æ‹‰æ¾ã€ç‘œä¼½è¯¾ï¼‰
       - **å®£ä¼ å€¡å¯¼ç±»**ï¼ˆå¦‚ç¯ä¿å€¡è®®ã€å…¬ç›Šå®£ä¼ ã€å¿ƒç†å¥åº·å‘¨ï¼‰

    2. **ä¼˜åŒ–ä¸å®šå‹**ï¼š
       - ä¿æŒç”¨æˆ·æè¿°çš„**æ ¸å¿ƒå…ƒç´ å’ŒåŸæ„**ã€‚
       - å°†è¯­è¨€ä¼˜åŒ–å¾—æ›´å¯Œæœ‰**è§†è§‰å†²å‡»åŠ›ã€æ„ŸæŸ“åŠ›å’Œé’æ˜¥æ°”æ¯**ï¼Œé€‚åˆæµ·æŠ¥ä¼ æ’­ã€‚
       - æ ¹æ®ä½ åˆ¤æ–­çš„æ´»åŠ¨ç±»å‹ï¼Œåœ¨æç¤ºè¯æœ«å°¾**è‡ªåŠ¨æ·»åŠ æœ€åŒ¹é…çš„é£æ ¼åç¼€**ã€‚

    3. **æ·»åŠ é£æ ¼åç¼€ç¤ºä¾‹**
       - å­¦æœ¯ç±»ï¼š`, academic poster, clean layout, infographic style, vector illustration, vibrant, 4k`
       - æ‹›å‹Ÿç±»ï¼š`, recruitment poster, dynamic composition, bold typography, team spirit, flat design, vibrant colors`
       - æ–‡è‰ºç±»ï¼š`, artistic poster, dramatic lighting, creative, painting style, trending on artstation, 8k`
       - åº†å…¸ç±»ï¼š`, festive poster, joyful atmosphere, confetti, glowing lights, vector art, bright color palette`
       - ä½“è‚²ç±»ï¼š`, sports poster, action shot, motion blur, energetic, strong contrast, graphic design`
       - å®£ä¼ å€¡å¯¼ç±»ï¼š`, public awareness poster, symbolic, minimalist, powerful message, solid background`

    ã€ç”¨æˆ·æè¿°ã€‘
    {prompt}

    ã€ä½ çš„è¾“å‡ºã€‘
    è¯·ç›´æ¥è¾“å‡ºä»¥ä¸‹ä¸¤éƒ¨åˆ†å†…å®¹ï¼Œç”¨"---"åˆ†éš”ï¼š
    ç¬¬ä¸€éƒ¨åˆ†ï¼šä»…ä¸€å¥è¯è¯´æ˜"åˆ¤æ–­ä¸ºï¼šã€ç±»å‹ã€‘ç±»æ´»åŠ¨æµ·æŠ¥"ã€‚
    ç¬¬äºŒéƒ¨åˆ†ï¼šç›´æ¥ç»™å‡ºä¼˜åŒ–å¹¶æ·»åŠ äº†å¯¹åº”é£æ ¼åç¼€çš„å®Œæ•´è‹±æ–‡æç¤ºè¯ã€‚
    """
)
# åˆ›å»ºå¯è¿è¡Œé“¾ï¼šprompt -> llm
chain_review = review_prompt | llm

# ==================== 3. å°†æ™ºèƒ½ä½“ä¸²è”æˆååŒå·¥ä½œæµ ====================
# å®šä¹‰å®Œæ•´çš„å¤„ç†æµæ°´çº¿
overall_chain = RunnableSequence(
    # ç¬¬ä¸€æ­¥ï¼šæ¥æ”¶åˆå§‹è¾“å…¥ï¼Œä¼ é€’ç»™æ‹†è§£é“¾
    RunnablePassthrough.assign(decomposed_text=lambda x: chain_decompose.invoke(x)),
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ä¸Šä¸€æ­¥çš„è¾“å‡ºå»ä¼˜åŒ–
    lambda x: {"optimized_prompt": chain_optimize.invoke(x["decomposed_text"])},
    # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨ä¼˜åŒ–åçš„è¾“å‡ºå»å®¡æŸ¥/é£æ ¼åŒ–
    lambda x: {"final_prompt": chain_review.invoke(x["optimized_prompt"])}
)

# ==================== 4. å®šä¹‰Gradioç•Œé¢äº¤äº’å‡½æ•° ====================
def generate_poster(user_input):
    """ å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œè¿è¡Œæ™ºèƒ½ä½“é“¾ï¼Œå¹¶è¿”å›ç»“æœ """
    try:
        # 1. è¿è¡Œæ•´ä¸ªååŒé“¾
        # ç°åœ¨ overall_chain æ˜¯ä¸€ä¸ª RunnableSequenceï¼Œå¯ç›´æ¥è°ƒç”¨
        result = overall_chain.invoke({"user_input": user_input})

        # 2. ä»ç»“æœå­—å…¸ä¸­å®‰å…¨åœ°æå–æ¯ä¸ªç¯èŠ‚çš„æ–‡æœ¬å†…å®¹
        # æ³¨æ„ï¼šchain.invoke() è¿”å›çš„æ˜¯ AIMessage å¯¹è±¡ï¼Œéœ€è¦ç”¨ .content è·å–æ–‡æœ¬
        decomposed_text = result.get("decomposed_text", "").content if hasattr(result.get("decomposed_text"), 'content') else str(result.get("decomposed_text", ""))
        optimized_prompt = result.get("optimized_prompt", "").content if hasattr(result.get("optimized_prompt"), 'content') else str(result.get("optimized_prompt", ""))
        final_prompt = result.get("final_prompt", "").content if hasattr(result.get("final_prompt"), 'content') else str(result.get("final_prompt", ""))

        # 3. ï¼ˆåç»­ï¼‰æ­¤å¤„åº”è°ƒç”¨å›¾åƒç”ŸæˆAPIï¼Œç”¨ final_prompt ç”Ÿæˆå›¾ç‰‡
        image_output = None

        # 4. è¿”å›ç»™Gradioæ˜¾ç¤º
        return decomposed_text, optimized_prompt, final_prompt, image_output

    except Exception as e:
        # å¼‚å¸¸å¤„ç†ï¼šå°†é”™è¯¯ä¿¡æ¯è¿”å›ç»™ç•Œé¢ï¼Œæ–¹ä¾¿è°ƒè¯•
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
        return error_msg, error_msg, error_msg, None

# ==================== 5. æ„å»ºå¹¶å¯åŠ¨Gradio Webç•Œé¢ ====================
with gr.Blocks(title="SynthPoster") as demo:
    gr.Markdown("# ğŸ¨ æ™ºæ±‡æµ·æŠ¥ æµ·æŠ¥åˆ›ä½œæ™ºèƒ½ä½“ååŒç³»ç»Ÿ")
    gr.Markdown("ä½“éªŒä¸‰ä¸ªAIæ™ºèƒ½ä½“å¦‚ä½•ååŒå·¥ä½œï¼šæ‹†è§£ â†’ ä¼˜åŒ– â†’ é£æ ¼åŒ–")

    with gr.Row():
        with gr.Column():
            user_input = gr.Textbox(
                label="æè¿°ä½ æƒ³ç”Ÿæˆçš„æµ·æŠ¥",
                placeholder="ä¾‹å¦‚ï¼šAIæ¨¡å‹ååŒè®²åº§",
                lines=3
            )
            btn = gr.Button("ğŸš€ å¼€å§‹ååŒåˆ›ä½œ", variant="primary")

        with gr.Column():
            output_image = gr.Image(label="ç”Ÿæˆçš„æµ·æŠ¥", width=512)

    with gr.Accordion("ğŸ“ ç‚¹å‡»æŸ¥çœ‹æ™ºèƒ½ä½“ååŒçš„å®Œæ•´è¿‡ç¨‹", open=False):
        output_decomposed = gr.Textbox(label="æ™ºèƒ½ä½“1 - åˆ›æ„æ‹†è§£", lines=3)
        output_optimized = gr.Textbox(label="æ™ºèƒ½ä½“2 - æç¤ºè¯ä¼˜åŒ–", lines=3)
        output_final = gr.Textbox(label="æ™ºèƒ½ä½“3 - é£æ ¼å®šç¨¿", lines=3)

    # ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
    btn.click(
        fn=generate_poster,
        inputs=[user_input],
        outputs=[output_decomposed, output_optimized, output_final, output_image]
    )

    gr.Markdown("### ğŸ’¡ è¯´æ˜ï¼šå½“å‰ä½¿ç”¨å ä½å›¾ç‰‡ã€‚é›†æˆå›¾åƒAPIåï¼Œå³å¯ç”ŸæˆçœŸå®å›¾åƒã€‚")
    
    # æ·»åŠ æµ‹è¯•éƒ¨åˆ†
    gr.Markdown("## ç½‘ç»œè¯Šæ–­å·¥å…·")
    test_btn = gr.Button("è¿è¡Œç½‘ç»œæµ‹è¯•")
    test_output = gr.Textbox(label="æµ‹è¯•ç»“æœ", lines=10)
    test_btn.click(network_test, outputs=test_output)

     # ==================== æ–°å¢ï¼šAPIè¿é€šæ€§æµ‹è¯•åŠŸèƒ½åŒº ====================
    with gr.Accordion("ğŸ”§ APIè¿é€šæ€§æµ‹è¯•ï¼ˆè°ƒè¯•ä¸“ç”¨ï¼‰", open=False):
        gr.Markdown("""
        **ä½¿ç”¨è¯´æ˜**ï¼šæ­¤åŠŸèƒ½å°†ç»•è¿‡LangChainï¼Œç›´æ¥è°ƒç”¨ä½ é…ç½®çš„åƒé—®APIã€‚
        1. ç‚¹å‡»æµ‹è¯•æŒ‰é’®ã€‚
        2. ä¸‹æ–¹å°†æ˜¾ç¤ºï¼š**ä½ çš„é…ç½®**ã€**APIåŸå§‹å“åº”**ã€**å¤„ç†åçš„ç­”æ¡ˆ**ã€‚
        3. å¦‚æœå¤±è´¥ï¼Œä¼šæ˜¾ç¤ºå…·ä½“é”™è¯¯ï¼Œè¯·æ ¸å¯¹é…ç½®ï¼ˆç‰¹åˆ«æ˜¯Base URLå’Œæ¨¡å‹åï¼‰ã€‚
        """)
        test_btn = gr.Button("ğŸ§ª æµ‹è¯•APIè¿æ¥", variant="secondary")
        test_output_config = gr.Textbox(label="ä½ çš„APIé…ç½®", lines=3, interactive=False)
        test_output_raw = gr.Textbox(label="APIåŸå§‹å“åº”", lines=5, interactive=False)
        test_output_content = gr.Textbox(label="å¤„ç†åçš„å›ç­”", lines=2, interactive=False)

        # å®šä¹‰æµ‹è¯•å‡½æ•°
        def test_api_connection():
            config_info = f"""æ­£åœ¨æµ‹è¯•çš„é…ç½®ï¼š
    API_KEYå‰5ä½: {LLM_API_KEY[:5] if LLM_API_KEY else 'None'}...
    BASE_URL: {LLM_BASE_URL}
    MODEL_NAME: {LLM_MODEL_NAME}
    """
            try:
                # ç¡®ä¿åœ¨å‡½æ•°å†…å¯è®¿é—® openai æ¨¡å—
                import openai
                
                # 1. åˆå§‹åŒ–openaiå®¢æˆ·ç«¯
                client = openai.OpenAI(
                    api_key=LLM_API_KEY,
                    base_url=LLM_BASE_URL.rstrip('/')  # ç§»é™¤æœ«å°¾å¯èƒ½å­˜åœ¨çš„æ–œæ 
                )
                
                # 2. å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                test_messages = [{"role": "user", "content": "è¯·ç”¨ä¸­æ–‡ç®€çŸ­å›å¤ï¼šAPIè¿æ¥æµ‹è¯•æˆåŠŸã€‚"}]
                # è®¾ç½®æ˜ç¡®çš„è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´æŒ‚èµ·
                response = client.chat.completions.create(
                    model=LLM_MODEL_NAME,
                    messages=test_messages,
                    temperature=0.7,
                    timeout=10.0  # 10ç§’è¶…æ—¶
                )
                
                # 3. æ•´ç†å¹¶è¿”å›ç»“æœ
                raw_response = f"å“åº”å¯¹è±¡ç±»å‹: {type(response)}\n"
                raw_response += f"æ˜¯å¦æ”¶åˆ°å“åº”: {hasattr(response, 'choices')}\n"
                if hasattr(response, 'choices') and len(response.choices) > 0:
                    raw_response += f"choices ç»“æ„: {response.choices[0]}"
                
                answer = response.choices[0].message.content
                return config_info, raw_response, answer
                
            except openai.AuthenticationError as e:
                error_detail = f"{config_info}\n\nâŒ è®¤è¯å¤±è´¥ (å¯èƒ½åŸå› ):\n1. API_KEY æ— æ•ˆæˆ–å·²è¿‡æœŸ\n2. æœªå¼€é€šå¯¹åº”æ¨¡å‹æœåŠ¡\n3. æœåŠ¡åŒºåŸŸä¸æ­£ç¡®\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "è®¤è¯å¤±è´¥"
            except openai.NotFoundError as e:
                error_detail = f"{config_info}\n\nâŒ æœªæ‰¾åˆ°èµ„æº (å¯èƒ½åŸå› ):\n1. MODEL_NAME '{LLM_MODEL_NAME}' ä¸æ­£ç¡®\n2. BASE_URL è·¯å¾„é”™è¯¯\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "æ¨¡å‹æˆ–ç«¯ç‚¹ä¸å­˜åœ¨"
            except openai.APIConnectionError as e:
                error_detail = f"{config_info}\n\nğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥ (å¯èƒ½åŸå› ):\n1. BASE_URL æ— æ³•è®¿é—®\n2. ç½‘ç»œä»£ç†é—®é¢˜\n3. Hugging Face Space å®¹å™¨ç½‘ç»œé™åˆ¶\n\né”™è¯¯è¯¦æƒ…: {e}"
                return error_detail, str(e), "ç½‘ç»œè¿æ¥å¤±è´¥"
            except Exception as e:
                error_detail = f"{config_info}\n\nâš ï¸ æœªé¢„æœŸçš„é”™è¯¯:\né”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯è¯¦æƒ…: {str(e)}"
                return error_detail, str(e), f"è°ƒç”¨å¤±è´¥: {type(e).__name__}"
        
        # ç»‘å®šæµ‹è¯•æŒ‰é’®äº‹ä»¶
        test_btn.click(
            fn=test_api_connection,
            inputs=[],
            outputs=[test_output_config, test_output_raw, test_output_content]
        )

# è¿è¡Œ
if __name__ == "__main__":
    # åˆ¤æ–­æ˜¯å¦åœ¨ Hugging Face Space ç¯å¢ƒä¸­è¿è¡Œ
    if os.getenv("SPACE_ID") is not None:
        # ğŸš€ Space ç¯å¢ƒï¼šä½¿ç”¨é»˜è®¤çš„ launch() é…ç½®ï¼Œæ— éœ€ä»»ä½•å‚æ•°
        # Space ä¼šè‡ªåŠ¨å¤„ç†ç½‘ç»œã€ç«¯å£ç­‰æ‰€æœ‰é…ç½®
        demo.launch()
    else:
        # ğŸ’» æœ¬åœ°å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨ä½ åŸæ¥çš„é…ç½®
        demo.launch(server_name="127.0.0.1", server_port=7860, share=False)